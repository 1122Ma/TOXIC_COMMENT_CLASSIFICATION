# TOXIC_COMMENT_CLASSIFICATION
In the internet today Many people stop speaking up and give up on seeking out other viewpoints because they are afraid of being harassed and abused online. The inability of platforms to support conversations well has led to several communities limiting or removing user comments that lead someone leave a discussion.

We are tasked with creating a model in our project that can recognize many forms of toxicity, motivated by an individual's identity, We anticipate that this modifications to our approach will encourage online dialogue to improve in both content and interaction between people.

![image](https://github.com/1122Ma/TOXIC_COMMENT_CLASSIFICATION/assets/108218379/12ec4a65-15dc-4688-a7e0-7248b4868dcc)
